
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>PRT Blog</title>
  <meta name="author" content="Kenneth Morton and Peter Torrione">

  
  <meta name="description" content="Pattern Recognition in MATLAB The Pattern Recognition Toolbox for MATLAB® provides an easy to use and robust interface to dozens of pattern &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://newfolder.github.io/blog/page/13">
  <link href="/favicon.ico" rel="icon">
  
  <link href="/assets/bootstrap/css/spacelab.min.css" rel="stylesheet" type="text/css">
  <link href="/assets/bootstrap/css/bootstrap-responsive.min.css" rel="stylesheet" type="text/css">
  <link href="/assets/bootstrap/css/custom.css" rel="stylesheet" type="text/css">
  <link href="/assets/font-awesome/css/font-awesome.css" rel="stylesheet" type="text/css">
  
  <link href="/atom.xml" rel="alternate" title="PRT Blog" type="application/atom+xml">
  <style type="text/css">
pre, tt, code { font-size:12px; }
pre { margin:0px 0px 20px; }
pre.error { color:red; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
</style>
  

</head>

<body    data-spy="scroll">

  <div class="container">
    <header class="jumbotron subhead" id="overview">
      
<div class="subscribe">
  <table>
    <tr>
      <td><span>Get Updates: &nbsp;</span></td>
      
      
      <td><a href="/atom.xml" class="btn"><i class="icon-cog"></i> By RSS</a></td>
      
      
    </tr>
  </table>
</div>

<h1 class="title">PRT Blog</h1>

  <p class="lead">MATLAB Pattern Recognition Open Free and Easy</p>


      <div class="navbar">
  <div class="navbar-inner">
    <div class="container" style="width: auto;">
      <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </a>
      <div class="nav-collapse">
                <ul class="nav">
          <li><a href="/">Home</a></li>
          <li><a href="/blog/archives">Blog</a></li>
          <li><a href="https://github.com/newfolder/PRT">Code</a></li>
          <li><a href="/prtdoc/">Documentation</a></li>
		  <li><a href="https://github.com/newfolder/PRT/issues">Get Help</a><li>
          <li><a href="/about">About</a></li>
        </ul>

        
          <form action="http://google.com/search" method="get" class="navbar-search pull-left">
            <fieldset role="search">
              <input type="hidden" name="q" value="site:newfolder.github.io" />
              <input type="text" name="q" results="0" placeholder="Search" class="search-query span2" />
            </fieldset>
          </form>
        
        
      </div><!-- /.nav-collapse -->
    </div>
  </div><!-- /navbar-inner -->
</div>

    </header>
    <div id="main">
      <div id="content">
        <div class="row-fluid">
<div class="span8">
<div class="thumbnail pull-right" style="margin-left: 20px; width: 250px; height: 200px;"><img src="/images/prtIcon.png" alt="PRT Logo" width='250' height='200'></div>
<H1> Pattern Recognition in MATLAB </H1>
<p>The Pattern Recognition Toolbox for MATLAB® provides an easy to use and robust interface to dozens of pattern classification tools making cross-validation, data exploration, and classifier development rapid and simple. The PRT gives you the power to apply sophisticated data analysis techniques to your problem. If you have data and need to make predictions based on your data, the PRT can help you do more in less time.</p>

<H2>Visualize Your Data</H2>
<p>The PRT’s prtDataSet objects make using and visualizing your data a breeze. The multiple built in techniques for data visualization will help you interactively understand your data and develop the insights to help you make breakthroughs.</p>

<H2>Streamline Your Processing</H2>
<p>The PRT provides a wide array of inter-connectable pattern recognition approaches. Every PRT action can be connected to any other PRT actions to enable you to build the powerful processing pipelines to solve the problems you need to solve with a single tool.</p>

<H2>Get Answers</H2>
<p>Built in cross-validation techniques ensure that your performance estimates are robust, and are indicative of expected operating performance, and built in support for decision making takes the guesswork out of setting optimal thresholds to make binary or M-ary decisions based on your data.</p>
</div>


  <div class="span3 sidebar">
    <div class="well">
      
        <section>
  <h2>Recent Posts</h2>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/10/09/dude-wheres-my-help/">Dude Where&#8217;s My Help?</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/09/04/verbosestorage-and-a-little-prtalgorithm-plotting/">verboseStorage and a little prtAlgorithm plotting</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/08/20/introducing-prtclassnnet/">Introducing prtClassNNET</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/29/supervised-learning/">Supervised Learning: An Introduction for Scientists and Engineers</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/24/using-svms/">Using SVMs for Scientists and Engineers</a>
      </li>
    
  </ul>
</section>


      
    </div>
  </div>



</div>

<br>
<hr>
<br>

<H1>Latest Post</H1>

<div class="blog-index">
  
  
  
    <article>
      <br>

  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/22/prtkernel/">prtKernel</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-22T15:37:00-04:00" pubdate data-updated="true">Apr 22<span>nd</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>One of the commonly overlooked &#8220;actions&#8221; in the PRT is prtKernel. They are used internally in several places (RVM, SVM) but they can also be used by themselves. Let&#8217;s talk about em.</p>




<h2>Contents</h2>


<div><ul><li><a href="#1">Just Another Action</a></li><li><a href="#3">Let&#8217;s see what some other kernel transformations look like.</a></li><li><a href="#5">Kernel Sets</a></li><li><a href="#7">Inside the RVM</a></li><li><a href="#9">Outside of the RVM</a></li><li><a href="#10">Conclusions</a></li></ul></div>


<h2>Just Another Action<a name="1"></a></h2>


<p>Kernels have very precise meanings in certain contexts (Mercer kernels for example) so it is important that we really define what we mean by prtKernel. A prtKernel is a standard prtAction. That means that it supports the train operation, that takes a dataset and outputs a prtKernel with modified parameters, and the run operation, that takes a dataset and outputs modified dataset. What makes prtKernel different than other prtActions is that they typically transform a dataset into a different dimensionality. The new features are usually the distance to a collection of training examples and most kernels differ in their selection of the distance function. The most widely used kernel is the <a href="http://en.wikipedia.org/wiki/Radial_basis_function">radial basis function</a>.</p>


<p>Let&#8217;s look at using prtKernelRbf.</p>


<pre class="codeinput">ds = prtDataGenBimodal;
kernel = prtKernelRbf(<span class="string">'sigma'</span>,2); <span class="comment">% Set the kernel Parameter</span>
trainedKernel = kernel.train(ds); <span class="comment">% Train the kernel using the input data</span>
kernelTransformedData = trainedKernel.run(ds);

subplot(2,1,1)
plot(ds);
subplot(2,1,2)
imagesc(kernelTransformedData.X);
colormap(hot)
title(<span class="string">'Kernel Transformation'</span>);
ylabel(<span class="string">'observation'</span>);
xlabel(<span class="string">'feature'</span>)
</pre>


<p><img vspace="5" hspace="5" src="/images/morton_blog_20130421_01.png" alt=""> <p>You can see in the image space that there is a checkerboard pattern highlighting the multi-modal nature of the data.</p><h2>Let&rsquo;s see what some other kernel transformations look like.<a name="3"></a></h2><pre class="codeinput">kernelRbf = prtKernelRbf(<span class="string">&lsquo;sigma&rsquo;</span>,2);
trainedKernelRbf = kernelRbf.train(ds);
kernelTransformedDataRbf = trainedKernelRbf.run(ds);</p>

<p>subplot(2,2,1)
imagesc(kernelTransformedDataRbf.X);
title(<span class="string">&lsquo;RBF Kernel Transformation&rsquo;</span>);
ylabel(<span class="string">&lsquo;observation&rsquo;</span>);
xlabel(<span class="string">&lsquo;feature&rsquo;</span>)</p>

<p>kernelHyp = prtKernelHyperbolicTangent;
trainedKernelHyp = kernelHyp.train(ds);
kernelTransformedDataHyp = trainedKernelHyp.run(ds);</p>

<p>subplot(2,2,2)
imagesc(kernelTransformedDataHyp.X);
title(<span class="string">&lsquo;Hyperbolic Tangent Kernel Transformation&rsquo;</span>);
ylabel(<span class="string">&lsquo;observation&rsquo;</span>);
xlabel(<span class="string">&lsquo;feature&rsquo;</span>)</p>

<p>kernelPoly = prtKernelPolynomial;
trainedKernelPoly = kernelPoly.train(ds);
kernelTransformedDataPoly = trainedKernelPoly.run(ds);</p>

<p>subplot(2,2,3)
imagesc(kernelTransformedDataPoly.X);
title(<span class="string">&lsquo;Polynomial Kernel Transformation&rsquo;</span>);
ylabel(<span class="string">&lsquo;observation&rsquo;</span>);
xlabel(<span class="string">&lsquo;feature&rsquo;</span>)</p>

<p>kernelDirect  = prtKernelDirect;
trainedKernelDirect = kernelDirect.train(ds);
kernelTransformedDataDirect = trainedKernelDirect.run(ds);</p>

<p>subplot(2,2,4)
imagesc(kernelTransformedDataDirect.X);
title(<span class="string">&lsquo;Direct Kernel Transformation&rsquo;</span>);
ylabel(<span class="string">&lsquo;observation&rsquo;</span>);
xlabel(<span class="string">&lsquo;feature&rsquo;</span>)
</pre><img vspace="5" hspace="5" src="/images/morton_blog_20130421_02.png" alt=""> <p>You can see how the choice of the kernel (and kernel parameters) can really effect the outcoming feature space. It is also interesting to notice that the direct kernel is not actually a kernel at all. It just uses the data as the output featurespace (essentially doing nothing). This is useful for combining the original feature space with kernel transformed data using kernel sets.</p><h2>Kernel Sets<a name="5"></a></h2><p>Kernels can be combined using the &amp; operator to great prtKernelSets. These perform collumn wise concatonation of several kernels. This allows one to create a single kernel transformation out of several prtKernels. In theory one could use / to make a parallel prtAlgorithm to accomplish the same task but there are several reasons to use &amp; that allow them to work within the prtClassRvm and prtClassSvm to remain efficient at run-time.</p><pre class="codeinput">clf; <span class="comment">% Clear those subplots from earlier</span>
kernel = prtKernelDc &amp; prtKernelRbf(<span class="string">&lsquo;sigma&rsquo;</span>,1) &amp; prtKernelHyperbolicTangent;
trainedKernel = kernel.train(ds); <span class="comment">% Train the kernel using the input data</span>
kernelTransformedData = trainedKernel.run(ds);
imagesc(kernelTransformedData.X);
title(<span class="string">&lsquo;A Kernel Set Transformation&rsquo;</span>);
ylabel(<span class="string">&lsquo;observation&rsquo;</span>);
xlabel(<span class="string">&lsquo;feature&rsquo;</span>)
</pre><img vspace="5" hspace="5" src="/images/morton_blog_20130421_03.png" alt=""> <p>You can see that the different transformed feature spaces are concatenated together.</p><h2>Inside the RVM<a name="7"></a></h2><p>In prtClassRvm the &ldquo;kernels&rdquo; property can be set to the prtKernel of our choosing. The RVM is essentially a sparse (it tries to have most coefficients be zero) linear classifier that opperates on kernel transformed data. Let&rsquo;s look at some classification results of prtDataGenBimodal using several different choices for the kernel.</p><pre class="codeinput">subplot(2,2,1)
plot(train(prtClassRvm(<span class="string">&lsquo;kernels&rsquo;</span>,prtKernelRbf(<span class="string">&lsquo;sigma&rsquo;</span>,2)),ds))
title(<span class="string">&lsquo;RBF Kernel RVM&rsquo;</span>);</p>

<p>subplot(2,2,2)
plot(train(prtClassRvm(<span class="string">&lsquo;kernels&rsquo;</span>,prtKernelHyperbolicTangent),ds))
title(<span class="string">&lsquo;Hyperbolic Tangent Kernel RVM&rsquo;</span>);</p>

<p>subplot(2,2,3)
plot(train(prtClassRvm(<span class="string">&lsquo;kernels&rsquo;</span>,prtKernelPolynomial),ds))
title(<span class="string">&lsquo;Polynomial Kernel RVM&rsquo;</span>);</p>

<p>subplot(2,2,4)
plot(train(prtClassRvm(<span class="string">&lsquo;kernels&rsquo;</span>,prtKernelDirect),ds))
title(<span class="string">&lsquo;Direct Kernel RVM&rsquo;</span>);
</pre><img vspace="5" hspace="5" src="/images/morton_blog_20130421_04.png" alt=""> <p>As you can see the correct choice for the kernel is very important for robust classifcation. The RBF kenerl is a common choice but even it has the sigma parameter which can grealy impact performance. One interesting variant of the RBF kernel is call prtKernelRbfNeighborhoodScaled. This kernel sets the sigma parameter differently for each data point depending on the local neighborhood of the training point.</p><pre class="codeinput">clf; <span class="comment">% Clear those subplots from earlier</span>
plot(train(prtClassRvm(<span class="string">&lsquo;kernels&rsquo;</span>,prtKernelRbfNeighborhoodScaled),ds))
title(<span class="string">&lsquo;Locally Scaled RBF Kernel RVM&rsquo;</span>);
</pre><img vspace="5" hspace="5" src="/images/morton_blog_20130421_05.png" alt=""> <h2>Outside of the RVM<a name="9"></a></h2><p>In the forum the other day someone asked if we could do non-linear regression with multi-dimensional output. Sadly, the answer is &ldquo;not directly&rdquo; but using kernels you can. By transforming the data to kernel space and then using a linear regression technique you can perform non-linear regression. I wont copy the content over here but check out the answer from the forum. <a href="http://www.newfolderconsulting.com/node/412"><a href="http://www.newfolderconsulting.com/node/412">http://www.newfolderconsulting.com/node/412</a></a></p><h2>Conclusions<a name="10"></a></h2><p>This was a pretty quick overview of things you can do with kernels in the PRT. We don&rsquo;t have every kernel but we have quite a few. If there is something you think we should add let us know.</p></p>
</div>
  
  


<br>
<hr>
<br>
    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/14/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/12/">Newer &rarr;</a>
    
  </div>
</div>


      </div>
    </div>
    <footer class="footer"><p>
  Copyright &copy; 2013 - Kenneth Morton and Peter Torrione -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span> -
  
    <span class="credit">Theme by <a href="http://brianarmstrong.org">Brian Armstrong</a></span>
  
</p>
</footer>
    

<script type="text/javascript">
      var disqus_shortname = 'newfolderconsulting';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
<script src="/assets/bootstrap/js/bootstrap.min.js"></script>


  </div>
</body>
</html>
