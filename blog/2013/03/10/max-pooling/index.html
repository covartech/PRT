
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Max-Pooling Feature Representations in MSRCORID - PRT Blog</title>
  <meta name="author" content="Kenneth Morton and Peter Torrione">

  
  <meta name="description" content="Max-Pooling Feature Representations in MSRCORID Mar 10th, 2013 A few weeks ago we took a look at a paper by Coates and Ng that dealt with learning &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://newfolder.github.io/blog/2013/03/10/max-pooling">
  <link href="/favicon.ico" rel="icon">
  
  <link href="/assets/bootstrap/css/spacelab.min.css" rel="stylesheet" type="text/css">
  <link href="/assets/bootstrap/css/bootstrap-responsive.min.css" rel="stylesheet" type="text/css">
  <link href="/assets/bootstrap/css/custom.css" rel="stylesheet" type="text/css">
  <link href="/assets/font-awesome/css/font-awesome.css" rel="stylesheet" type="text/css">
  
  <link href="/atom.xml" rel="alternate" title="PRT Blog" type="application/atom+xml">
  <style type="text/css">
pre, tt, code { font-size:12px; }
pre { margin:0px 0px 20px; }
pre.error { color:red; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
</style>
  

</head>

<body    data-spy="scroll">

  <div class="container">
    <header class="jumbotron subhead" id="overview">
      
<div class="subscribe">
  <table>
    <tr>
      <td><span>Get Updates: &nbsp;</span></td>
      
      
      <td><a href="/atom.xml" class="btn"><i class="icon-cog"></i> By RSS</a></td>
      
      
    </tr>
  </table>
</div>

<h1 class="title">PRT Blog</h1>

  <p class="lead">MATLAB Pattern Recognition Open Free and Easy</p>


      <div class="navbar">
  <div class="navbar-inner">
    <div class="container" style="width: auto;">
      <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </a>
      <div class="nav-collapse">
                <ul class="nav">
          <li><a href="/">Home</a></li>
          <li><a href="/blog/archives">Blog</a></li>
          <li><a href="https://github.com/newfolder/PRT">Code</a></li>
          <li><a href="/prtdoc/">Documentation</a></li>
		  <li><a href="https://github.com/newfolder/PRT/issues">Get Help</a><li>
          <li><a href="/about">About</a></li>
        </ul>

        
          <form action="http://google.com/search" method="get" class="navbar-search pull-left">
            <fieldset role="search">
              <input type="hidden" name="q" value="site:newfolder.github.io" />
              <input type="text" name="q" results="0" placeholder="Search" class="search-query span2" />
            </fieldset>
          </form>
        
        
      </div><!-- /.nav-collapse -->
    </div>
  </div><!-- /navbar-inner -->
</div>

    </header>
    <div id="main">
      <div id="content">
        <div class="row">
  
  <div class="span8">
    <br>

  <header>
    
      <h1 class="entry-title">Max-Pooling Feature Representations in MSRCORID</h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-03-10T18:13:00-04:00" pubdate data-updated="true">Mar 10<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>A few weeks ago we took a look at a paper by Coates and Ng that dealt with learning feature representations for image processing and classification.  (See: <a href="/blog/2013/02/27/learning-feature-representations/">this</a>). Today I want to take a second look at that paper, and especially what they mean by max-pooling over regions of the image.</p>


<!--/introduction-->




<h2>Contents</h2>


<div><ul><li><a href="#1">The MSRCORID Database</a></li><li><a href="#2">Max-Pooling</a></li><li><a href="#5">Multiple Classes</a></li><li><a href="#7">Conclusions</a></li><li><a href="#8">Bibliography</a></li></ul></div>


<h2>The MSRCORID Database<a name="1"></a></h2>


<p>If you have already read through <a href="/blog/2013/02/27/learning-feature-representations/">our previous post</a>, you know how to get the Microsoft Research Cambridge Object Recognition Image Database (MSRCORID), which is really a fantastic resource for image processing and classification.</p>


<p>Once you&#8217;ve downloaded, we can run the following code which was for the most-prt ripped right out of the previous blog post:</p>


<pre class="codeinput">ds = prtDataGenMsrcorid;

patchSize = [8 8];
col = [];
<span class="keyword">for</span> imgInd = 1:ds.nObservations;
    img = ds.X{imgInd};
    img = rgb2gray(img);
    img = imresize(img,.5);
    col = cat(1,col,im2col(img,patchSize,<span class="string">'distinct'</span>)');
<span class="keyword">end</span>
dsCol = prtDataSetClass(double(col));

preProc = prtPreProcZeroMeanRows + prtPreProcStdNormalizeRows(<span class="string">'varianceOffset'</span>,10) + prtPreProcZca;
preProc = preProc.train(dsCol);
dsNorm = preProc.run(dsCol);

skm = prtClusterSphericalKmeans(<span class="string">'nClusters'</span>,50);
skm = skm.train(dsNorm);
</pre>


<h2>Max-Pooling<a name="2"></a></h2>


<p>Last time, we used a simple bag-of-words model to do classification based on the feature vectors in each image.  That&#8217;s definitely an interesting way to proceed, but most image-processing techniques make use of something called &#8220;max-pooling&#8221; to aggregate feature vectors over small regions of an image.</p>


<p>The process can be accomplished in MATLAB using blockproc.m, which is in the Image-processing toolbox.  (If you don&#8217;t have image processing, it&#8217;s not too hard to write a replacement for blockproc.)</p>


<p>The goal of max-pooling is to aggregate feature vectors over local regions of an image.  For example, we can take the MAX of the cluster memberships over each 8x8 region in an image using something like:</p>


<p>featsBp = blockproc(feats,[8 8],@(x)max(max(x.data,[],1),[],2));</p>


<p>Where we&#8217;ve assumed that feats is size nx x ny x nFeats.</p>


<p>Max pooling is nice because it reduces the dependency of the feature vectors on their exact placement in an image (each element of each 8x8 block gets treated about the same), and it also maintains a lot of the information that was in each of the feature vectors, especially when the feature vectors are expected to be sparse (e.g., have a lot of zeros; see http//www.ece.duke.edu/~lcarin/Bo12.3.2010.ppt).</p>


<p>There&#8217;s a lot more to max-pooling than we have time to get into here, for example, you can max-pool, and then re-cluster, and then re-max-pool! This is actually a super clever technique to reduce the amount of spatial variation in your image, and also capture information about the relative placements of various objects.</p>


<pre class="codeinput">featVec = nan(ds.nObservations,skm.nClusters*20);
clusters = skm.run(dsNorm);

<span class="keyword">for</span> imgInd = 1:ds.nObservations;
    img = ds.X{imgInd};
    img = rgb2gray(img);
    imgSize = size(img);

    <span class="comment">% Extract the sub-patches</span>
    col = im2col(img,patchSize,<span class="string">'distinct'</span>);
    col = double(col);
    dsCol = prtDataSetClass(col');
    dsCol = run(preProc,dsCol);
    dsFeat = skm.run(dsCol);
    dsFeat.X = max(dsFeat.X,.05);

    <span class="comment">% Max Pool!</span>
    <span class="comment">%   Feats will be size 30 x 40 x nClusters</span>
    <span class="comment">%   featsBp will be size [4 x 5] x nClusters (because of the way</span>
    <span class="comment">%   blockproc handles edsges)</span>
    feats = reshape(dsFeat.X,imgSize(1)/8,imgSize(2)/8,[]);
    featsBp = blockproc(feats,[8 8],@(x)max(max(x.data,[],1),[],2));

    <span class="comment">% We'll cheat a little here, and use the whole max-pooled feature set</span>
    <span class="comment">% as our feature vector.  Instead, we might want to re-cluster, and</span>
    <span class="comment">% re-max-pool, and repeat this process a few times.  For now, we'll</span>
    <span class="comment">% keep it simple:</span>
    featVec(imgInd,:) = featsBp(:);
<span class="keyword">end</span>
</pre>


<p>Now that we&#8217;ve max-pooled, we can use our extracted features for classification - we&#8217;ll use a simple PLSDA + MAP classifier and decision algorithm here:</p>


<pre class="codeinput">dsFeat = prtDataSetClass(featVec,ds.targets);
dsFeat.classNames = ds.classNames;

yOut = kfolds(prtClassPlsda + prtDecisionMap,dsFeat,3);

close <span class="string">all</span>;
prtScoreConfusionMatrix(yOut)
</pre>


<p><img vspace="5" hspace="5" src="/images/torrione_ExampleCoatesNg_Kmeans_Mscorid_2_01.png" alt=""> <p>Almost 99% correct!  We&rsquo;ve improved performance over our previous work with bag-of-words models, and an SVM, by just (1) max-pooling, and (2) replacing the SVM with a PLSDA classifier.</p><h2>Multiple Classes<a name="5"></a></h2><p>Until now we&rsquo;ve focused on just two classes in MSRCORID.  But there are a lot of types of objects in the MSRCORID database.  In the following, we just repeat a bunch of the code from above, and run it on a data set containing images of benches, buildings, cars, chimneys, clouds and doors:</p><pre class="codeinput">ds = prtDataGenMsrcorid({<span class="string">&lsquo;benches_and_chairs&rsquo;</span>,<span class="string">&lsquo;buildings&rsquo;</span>,<span class="string">&lsquo;cars\front view&rsquo;</span>,<span class="string">&lsquo;cars\rear view&rsquo;</span>,<span class="string">&lsquo;cars\side view&rsquo;</span>,<span class="string">&lsquo;chimneys&rsquo;</span>,<span class="string">&lsquo;clouds&rsquo;</span>,<span class="string">&lsquo;doors&rsquo;</span>});</p>

<p>patchSize = [8 8];
col = [];
<span class="keyword">for</span> imgInd = 1:ds.nObservations;</p>

<pre><code>img = ds.X{imgInd};
img = rgb2gray(img);
img = imresize(img,.5);
col = cat(1,col,im2col(img,patchSize,&lt;span class="string"&gt;'distinct'&lt;/span&gt;)');
</code></pre>

<p><span class="keyword">end</span>
dsCol = prtDataSetClass(double(col));</p>

<p>preProc = prtPreProcZeroMeanRows + prtPreProcStdNormalizeRows(<span class="string">&lsquo;varianceOffset&rsquo;</span>,10) + prtPreProcZca;
preProc = preProc.train(dsCol);
dsNorm = preProc.run(dsCol);</p>

<p>skm = prtClusterSphericalKmeans(<span class="string">&lsquo;nClusters&rsquo;</span>,50);
skm = skm.train(dsNorm);</p>

<p>featVec = nan(ds.nObservations,skm.nClusters*20);
clusters = skm.run(dsNorm);</p>

<p><span class="keyword">for</span> imgInd = 1:ds.nObservations;</p>

<pre><code>img = ds.X{imgInd};
img = rgb2gray(img);
imgSize = size(img);

&lt;span class="comment"&gt;% Extract the sub-patches&lt;/span&gt;
col = im2col(img,patchSize,&lt;span class="string"&gt;'distinct'&lt;/span&gt;);
col = double(col);
dsCol = prtDataSetClass(col');
dsCol = run(preProc,dsCol);
dsFeat = skm.run(dsCol);
dsFeat.X = max(dsFeat.X,.05);

&lt;span class="comment"&gt;% Max Pool!&lt;/span&gt;
&lt;span class="comment"&gt;%   Feats will be size 30 x 40 x nClusters&lt;/span&gt;
&lt;span class="comment"&gt;%   featsBp will be size [4 x 5] x nClusters (because of the way&lt;/span&gt;
&lt;span class="comment"&gt;%   blockproc handles edsges)&lt;/span&gt;
feats = reshape(dsFeat.X,imgSize(1)/8,imgSize(2)/8,[]);
featsBp = blockproc(feats,[8 8],@(x)max(max(x.data,[],1),[],2));

&lt;span class="comment"&gt;% We'll cheat a little here, and use the whole max-pooled feature set&lt;/span&gt;
&lt;span class="comment"&gt;% as our feature vector.  Instead, we might want to re-cluster, and&lt;/span&gt;
&lt;span class="comment"&gt;% re-max-pool, and repeat this process a few times.  For now, we'll&lt;/span&gt;
&lt;span class="comment"&gt;% keep it simple:&lt;/span&gt;
featVec(imgInd,:) = featsBp(:);
</code></pre>

<p><span class="keyword">end</span></p>

<p>dsFeat = prtDataSetClass(featVec,ds.targets);
dsFeat.classNames = ds.classNames;</p>

<p>yOut = kfolds(prtClassPlsda(<span class="string">&lsquo;nComponents&rsquo;</span>,10) + prtDecisionMap,dsFeat,3);
yOut.classNames = cellfun(@(s)s(1:min([length(s),10])),yOut.classNames,<span class="string">&lsquo;uniformoutput&rsquo;</span>,false);
close <span class="string">all</span>;
prtScoreConfusionMatrix(yOut);
set(gcf,<span class="string">&lsquo;position&rsquo;</span>,[426   125   777   558]);
</pre><img vspace="5" hspace="5" src="/images/torrione_ExampleCoatesNg_Kmeans_Mscorid_2_02.png" alt=""> <p>Now we&rsquo;re doing some image processing!  Overall we got about 90% correct, and that includes a lot of confusions between cars\front and cars\rear. That makes sense since the front and backs of cars look pretty similar, and there are only 23 car front examples in the whole data set.</p><h2>Conclusions<a name="7"></a></h2><p>The code in a lot of this blog entry is pretty gross &ndash; for example we have to constantly be taking data out of, and putting it back into the appropriate image sizes.</p><p>At some point in the future, we&rsquo;d like to introduce a good prtDataSet that will handle cell-arrays containing images properly.  We&rsquo;re not there yet, but when we are, we&rsquo;ll let you know on this blog!</p><p>Happy coding!</p><h2>Bibliography<a name="8"></a></h2><p>Adam Coates and Andrew Y. Ng, Learning Feature Representations with K-means, G. Montavon, G. B. Orr, K.-R. Muller (Eds.), Neural Networks: Tricks of the Trade, 2nd edn, Springer LNCS 7700, 2012</p></p>
</div>


<br>
<hr>
<br>
    <footer>
      <p class="meta">
        
  

<span class="byline author vcard">Posted by <span class="fn">Pete</span></span>

        








  


<time datetime="2013-03-10T18:13:00-04:00" pubdate data-updated="true">Mar 10<span>th</span>, 2013</time>
        


      </p>
      
        <div class="sharing">
  <br/>
  
  
  
</div>

      
      <p class="meta">
        
          <a class="basic-alignment pull-left" href="/blog/2013/03/06/using-prtpath/" title="Previous Post: Using prtPath">&laquo; Using prtPath</a>
        
        
          <a class="basic-alignment pull-right" href="/blog/2013/03/19/feature-selection/" title="Next Post: Feature Selection - prtFeatSelSfs">Feature Selection - prtFeatSelSfs &raquo;</a>
        
      </p>
    </footer>
    
    
      <section>
        <h1>Comments</h1>
        <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
      </section>
    
  </div>

  
    
  <div class="span3 sidebar">
    <div class="well">
      
        <section>
  <h2>Recent Posts</h2>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/10/09/dude-wheres-my-help/">Dude Where's My Help?</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/09/04/verbosestorage-and-a-little-prtalgorithm-plotting/">verboseStorage and a little prtAlgorithm plotting</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/08/20/introducing-prtclassnnet/">Introducing prtClassNNET</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/29/supervised-learning/">Supervised Learning: An Introduction for Scientists and Engineers</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/24/using-svms/">Using SVMs for Scientists and Engineers</a>
      </li>
    
  </ul>
</section>


      
    </div>
  </div>


  
</div>


      </div>
    </div>
    <footer class="footer"><p>
  Copyright &copy; 2013 - Kenneth Morton and Peter Torrione -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span> -
  
    <span class="credit">Theme by <a href="http://brianarmstrong.org">Brian Armstrong</a></span>
  
</p>
</footer>
    

<script type="text/javascript">
      var disqus_shortname = 'newfolderconsulting';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://newfolder.github.io/blog/2013/03/10/max-pooling/';
        var disqus_url = 'http://newfolder.github.io/blog/2013/03/10/max-pooling/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
<script src="/assets/bootstrap/js/bootstrap.min.js"></script>


  </div>
</body>
</html>
