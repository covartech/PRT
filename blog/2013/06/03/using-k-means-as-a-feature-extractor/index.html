
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Using K-Means As a Feature Extractor - PRT Blog</title>
  <meta name="author" content="Kenneth Morton and Peter Torrione">

  
  <meta name="description" content="Using K-Means as a Feature Extractor Jun 3rd, 2013 Hi everyone, Today we&#8217;d like to talk about using K-Means as a non-linear feature extraction &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://newfolder.github.io/blog/2013/06/03/using-k-means-as-a-feature-extractor">
  <link href="/favicon.ico" rel="icon">
  
  <link href="/assets/bootstrap/css/spacelab.min.css" rel="stylesheet" type="text/css">
  <link href="/assets/bootstrap/css/bootstrap-responsive.min.css" rel="stylesheet" type="text/css">
  <link href="/assets/bootstrap/css/custom.css" rel="stylesheet" type="text/css">
  <link href="/assets/font-awesome/css/font-awesome.css" rel="stylesheet" type="text/css">
  
  <link href="/atom.xml" rel="alternate" title="PRT Blog" type="application/atom+xml">
  <style type="text/css">
pre, tt, code { font-size:12px; }
pre { margin:0px 0px 20px; }
pre.error { color:red; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
</style>
  

</head>

<body    data-spy="scroll">

  <div class="container">
    <header class="jumbotron subhead" id="overview">
      
<div class="subscribe">
  <table>
    <tr>
      <td><span>Get Updates: &nbsp;</span></td>
      
      
      <td><a href="/atom.xml" class="btn"><i class="icon-cog"></i> By RSS</a></td>
      
      
    </tr>
  </table>
</div>

<h1 class="title">PRT Blog</h1>

  <p class="lead">MATLAB Pattern Recognition Open Free and Easy</p>


      <div class="navbar">
  <div class="navbar-inner">
    <div class="container" style="width: auto;">
      <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </a>
      <div class="nav-collapse">
                <ul class="nav">
          <li><a href="/">Home</a></li>
          <li><a href="/blog/archives">Blog</a></li>
          <li><a href="https://github.com/newfolder/PRT">Code</a></li>
          <li><a href="/prtdoc/">Documentation</a></li>
		  <li><a href="https://github.com/newfolder/PRT/issues">Get Help</a><li>
          <li><a href="/about">About</a></li>
        </ul>

        
          <form action="http://google.com/search" method="get" class="navbar-search pull-left">
            <fieldset role="search">
              <input type="hidden" name="q" value="site:newfolder.github.io" />
              <input type="text" name="q" results="0" placeholder="Search" class="search-query span2" />
            </fieldset>
          </form>
        
        
      </div><!-- /.nav-collapse -->
    </div>
  </div><!-- /navbar-inner -->
</div>

    </header>
    <div id="main">
      <div id="content">
        <div class="row">
  
  <div class="span8">
    <br>

  <header>
    
      <h1 class="entry-title">Using K-Means as a Feature Extractor</h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-06-03T11:48:00-04:00" pubdate data-updated="true">Jun 3<span>rd</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Hi everyone,</p>


<p>Today we&#8217;d like to talk about using K-Means as a non-linear feature extraction algorithm.  This is becoming a pretty popular way to deal with a number of classification tasks, since K-means followed by linear classification is relatively easy to paralellize and works well on very large data sets.</p>


<p>We&#8217;ll leave the large data set processing to another time, and for now, just look at a new prtPreProc object - prtPreProcKmeans</p>




<!--/introduction-->


<h2>Contents</h2>


<div><ul><li><a href="#1">prtPreProcKmeans</a></li><li><a href="#2">Combining with Linear Classification</a></li><li><a href="#3">Visualizing</a></li><li><a href="#4">Wrapping Up</a></li></ul></div>


<h2>prtPreProcKmeans<a name="1"></a></h2>


<p>You may be used to using prtClusterKmeans previously, and wonder why we need prtPreProcKmeans - the answer is a little subtle.  prtCluster* objects are expected to output the max a-posteriori cluster assignments. But for feature extraction, we actually want to output the distances from each observation to each cluster center (vs. the class outputs).  You can see the difference in the following:</p>


<pre class="codeinput">ds = prtDataGenBimodal;
cluster = prtClusterKmeans(<span class="string">'nClusters'</span>,4);
preProc = prtPreProcKmeans(<span class="string">'nClusters'</span>,4);

cluster = cluster.train(ds);
preProc = preProc.train(ds);
dsCluster = cluster.run(ds);
dsPreProc = preProc.run(ds);

subplot(1,2,1);
imagesc(dsCluster);
title(<span class="string">'Cluster Assignments'</span>);
subplot(1,2,2);
imagesc(dsPreProc);
title(<span class="string">'Cluster Distances'</span>);
</pre>


<p><img vspace="5" hspace="5" src="/images/torrione_blog_2013_06_03_01.png" alt=""> <h2>Combining with Linear Classification<a name="2"></a></h2><p>We can combine prtPreProcKmeans with any classifier &ndash; let&rsquo;s try with a logistic discriminant, and see how well we can do:</p><pre class="codeinput">algoSimple = prtClassLogisticDiscriminant;
algoKmeans = prtPreProcKmeans(<span class="string">&lsquo;nClusters&rsquo;</span>,4) + prtClassLogisticDiscriminant;</p>

<p>yOutSimple = kfolds(algoSimple,ds,5);
yOutKmeans = kfolds(algoKmeans,ds,5);</p>

<p>yOutAll = catFeatures(yOutSimple,yOutKmeans);
[pf,pd] = prtScoreRoc(yOutAll);
subplot(1,1,1);
h = prtUtilCellPlot(pf,pd);
set(h,<span class="string">&lsquo;linewidth&rsquo;</span>,3);
legend(h,{<span class="string">&lsquo;Log Disc&rsquo;</span>,<span class="string">&lsquo;K-Means + Log-Disc&rsquo;</span>});
xlabel(<span class="string">&lsquo;Pfa&rsquo;</span>);
ylabel(<span class="string">&lsquo;Pd&rsquo;</span>);
</pre><img vspace="5" hspace="5" src="/images/torrione_blog_2013_06_03_02.png" alt=""> <h2>Visualizing<a name="3"></a></h2><p>We can visualize the resulting decision boundary using a hidden (and undocumented method) of prtAlgorithm, that lets us plot algorithms as though they were classifiers as long as certain conditions are met.</p><p>Here&rsquo;s an example:</p><pre class="codeinput">algoKmeans = algoKmeans.train(ds);
algoKmeans.plotAsClassifier;
title(<span class="string">&lsquo;K-Means + Logistic Discriminant&rsquo;</span>);
</pre><img vspace="5" hspace="5" src="/images/torrione_blog_2013_06_03_03.png" alt=""> <h2>Wrapping Up<a name="4"></a></h2><p>K-Means pre-processing is a potentially powerful way to combine simple clustering and simple classification algorithms to form powerful non-linear classifiers.</p><p>We&rsquo;re working on some big additions to the PRT in the next few weeks&hellip; especially dealing with very large data sets.  Stay tuned.</p></p>
</div>


<br>
<hr>
<br>
    <footer>
      <p class="meta">
        
  

<span class="byline author vcard">Posted by <span class="fn">Pete</span></span>

        








  


<time datetime="2013-06-03T11:48:00-04:00" pubdate data-updated="true">Jun 3<span>rd</span>, 2013</time>
        


      </p>
      
        <div class="sharing">
  <br/>
  
  
  
</div>

      
      <p class="meta">
        
          <a class="basic-alignment pull-left" href="/blog/2013/05/21/new-visualization-with-imagesc/" title="Previous Post: New Visualization with IMAGESC">&laquo; New Visualization with IMAGESC</a>
        
        
          <a class="basic-alignment pull-right" href="/blog/2013/06/13/prtclustermeanshift/" title="Next Post: prtClusterMeanShift">prtClusterMeanShift &raquo;</a>
        
      </p>
    </footer>
    
    
      <section>
        <h1>Comments</h1>
        <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
      </section>
    
  </div>

  
    
  <div class="span3 sidebar">
    <div class="well">
      
        <section>
  <h2>Recent Posts</h2>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/10/09/dude-wheres-my-help/">Dude Where's My Help?</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/09/04/verbosestorage-and-a-little-prtalgorithm-plotting/">verboseStorage and a little prtAlgorithm plotting</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/08/20/introducing-prtclassnnet/">Introducing prtClassNNET</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/29/supervised-learning/">Supervised Learning: An Introduction for Scientists and Engineers</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/24/using-svms/">Using SVMs for Scientists and Engineers</a>
      </li>
    
  </ul>
</section>


      
    </div>
  </div>


  
</div>


      </div>
    </div>
    <footer class="footer"><p>
  Copyright &copy; 2013 - Kenneth Morton and Peter Torrione -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span> -
  
    <span class="credit">Theme by <a href="http://brianarmstrong.org">Brian Armstrong</a></span>
  
</p>
</footer>
    

<script type="text/javascript">
      var disqus_shortname = 'newfolderconsulting';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://newfolder.github.io/blog/2013/06/03/using-k-means-as-a-feature-extractor/';
        var disqus_url = 'http://newfolder.github.io/blog/2013/06/03/using-k-means-as-a-feature-extractor/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
<script src="/assets/bootstrap/js/bootstrap.min.js"></script>


  </div>
</body>
</html>
